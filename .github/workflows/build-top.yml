name: Build & Publish Top Leaderboards (from official repo)

on:
  schedule:
    - cron: "15 5 * * *"   # tous les jours à 05:15 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout THIS repo (destination for JSON)
        uses: actions/checkout@v4

      - name: Clone upstream official data repo
        run: |
          rm -rf upstream
          git clone --depth=1 https://github.com/JonathanChavezTamales/llm-leaderboard.git upstream
          echo "Tree preview:"
          find upstream/data -maxdepth 2 -type d -print | sed 's/^/ - /'

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Build top-leaderboards.json (recursive scan + model_benchmarks support)
        run: |
          python - << 'PY'
          import os, json, math, re, datetime

          ROOT = "upstream/data"

          # -------------------- helpers --------------------
          def to_float(x):
              try: return float(x)
              except Exception: return None

          def normalize_score(v):
              f = to_float(v)
              if f is None: return None
              if f <= 1.0: f *= 100.0   # 0.884 -> 88.4
              return round(f, 1)

          def parse_tokens_value(n):
              if n >= 1_000_000: return f"{n/1_000_000:.1f}M tokens"
              if n >= 1_000:     return f"{int(n/1000)}K tokens"
              return f"{int(n)} tokens"

          PRICE_KEYS = [
              "input_cost_per_million","input_cost","price_per_million",
              "price_per_1m_input_tokens","input_cost_per_1m","price_per_million_tokens"
          ]
          TPS_KEYS   = ["tokens_per_second","throughput","tps","speed_tokens_per_second"]

          CODE_KEYS       = ["aider_polyglot","aider","code","coding","polyglot"]
          MULTI_KEYS      = ["mmmu","multimodal","vision"]
          KNOWLEDGE_KEYS  = ["gpqa","gpqa_diamond","knowledge"]
          CTX_KEYS        = ["context_length","max_context_length","input_context","context","window"]

          def best_of(dct, keys):
              scores = dct.get("scores") or {}
              if isinstance(scores, dict):
                  for k in keys:
                      if k in scores:
                          s = normalize_score(scores[k])
                          if s is not None: return s
              benches = dct.get("benchmarks") or {}
              if isinstance(benches, dict):
                  for k in keys:
                      b = benches.get(k)
                      if isinstance(b, dict) and "score" in b:
                          s = normalize_score(b["score"])
                          if s is not None: return s
                      elif b is not None:
                          s = normalize_score(b)
                          if s is not None: return s
              return None

          # -------------------- accumulators --------------------
          code_best, multi_best, know_best, ctx_best = {}, {}, {}, {}
          cheap_best, fast_best = {}, {}

          # helpers pour pousser un score si meilleur
          def push_best(map_, name, score):
              if score is None: return
              if name not in map_ or score > map_[name]:
                  map_[name] = score

          # -------------------- scan all JSON --------------------
          for root, _, files in os.walk(ROOT):
              for fn in files:
                  if not fn.endswith(".json"): 
                      continue
                  path = os.path.join(root, fn)
                  rel  = path.replace("\\","/")

                  # --- 1) cas spéciaux: model_benchmarks/*.json (LISTES!)
                  if "/model_benchmarks/" in rel:
                      try:
                          js = json.load(open(path,"r",encoding="utf-8"))
                      except Exception:
                          continue
                      if not isinstance(js, (list,dict)): 
                          continue

                      # Détection par nom de fichier
                      low = fn.lower()
                      bucket = None
                      if re.search(r"aider|polyglot|code", low): bucket = "code"
                      elif re.search(r"mmmu|multimodal|vision", low): bucket = "multimodal"
                      elif re.search(r"gpqa", low): bucket = "knowledge"

                      if not bucket:
                          continue

                      items=[]
                      if isinstance(js, list):
                          for it in js:
                              if not isinstance(it, dict): continue
                              nm = it.get("name") or it.get("model") or it.get("id")
                              sc = normalize_score(it.get("score") or it.get("value"))
                              if nm and sc is not None:
                                  items.append((nm, sc))
                      elif isinstance(js, dict):
                          for nm, sc in js.items():
                              sc = normalize_score(sc)
                              if sc is not None:
                                  items.append((nm, sc))

                      for nm, sc in items:
                          if bucket == "code":        push_best(code_best,  nm, sc)
                          elif bucket == "multimodal":push_best(multi_best, nm, sc)
                          elif bucket == "knowledge": push_best(know_best,  nm, sc)
                      continue

                  # --- 2) providers: listes de modèles avec prix / tps
                  try:
                      data = json.load(open(path, "r", encoding="utf-8"))
                  except Exception:
                      continue

                  if isinstance(data, list):
                      # deviner provider par chemin
                      prov = None
                      parts = rel.split("/")
                      if "provider_models" in parts:
                          try: prov = os.path.splitext(parts[parts.index("provider_models")+1])[0]
                          except Exception: prov = None
                      elif "providers" in parts:
                          try: prov = parts[parts.index("providers")+1]
                          except Exception: prov = None

                      if prov:
                          min_cost = cheap_best.get(prov, math.inf)
                          max_tps  = fast_best.get(prov, 0.0)
                          for m in data:
                              if not isinstance(m, dict): continue
                              for pk in PRICE_KEYS:
                                  cf = to_float(m.get(pk))
                                  if cf is not None and cf < min_cost:
                                      min_cost = cf
                              for tk in TPS_KEYS:
                                  tf = to_float(m.get(tk))
                                  if tf is not None and tf > max_tps:
                                      max_tps = tf
                          if min_cost != math.inf: cheap_best[prov] = min_cost
                          if max_tps  > 0:         fast_best[prov]  = max_tps
                      continue

                  # --- 3) models-ish: dicts avec scores/benchmarks/context
                  if isinstance(data, dict):
                      name = (data.get("name") or data.get("model") or data.get("id") 
                              or os.path.splitext(os.path.basename(path))[0])

                      push_best(code_best,  name, best_of(data, CODE_KEYS))
                      push_best(multi_best, name, best_of(data, MULTI_KEYS))
                      push_best(know_best,  name, best_of(data, KNOWLEDGE_KEYS))

                      # contexte
                      ctx_val = None
                      for ck in CTX_KEYS:
                          if ck in data and data[ck] not in (None, ""):
                              ctx_val = data[ck]; break
                      if ctx_val is not None:
                          v = to_float(ctx_val)
                          if v is None:
                              s = str(ctx_val).lower().replace("tokens","").strip()
                              mul = 1
                              if "m" in s: s=s.replace("m",""); mul = 1_000_000
                              elif "k" in s: s=s.replace("k",""); mul = 1_000
                              try: v = float(s)*mul
                              except Exception: v = None
                          if v and v > 0:
                              if name not in ctx_best or v > ctx_best[name]:
                                  ctx_best[name] = int(v)

          # -------------------- build final tops --------------------
          def top_from_map(dct, score=True, limit=5):
              if score:
                  items = [{"name":k,"score":v} for k,v in dct.items() if v is not None]
                  items.sort(key=lambda x:x["score"], reverse=True)
              else:
                  items = [{"name":k,"value":v} for k,v in dct.items() if v is not None]
              return items[:limit]

          code_list  = top_from_map(code_best,  True)
          multi_list = top_from_map(multi_best, True)
          know_list  = top_from_map(know_best,  True)

          ctx_items = sorted(ctx_best.items(), key=lambda kv: kv[1], reverse=True)
          longest_context = [{"name":k, "value": parse_tokens_value(v)} for k,v in ctx_items[:5]]

          cheapest_items = [{"name":k, "value": f"${v:.2f} / 1M tokens"} for k,v in cheap_best.items()]
          def cost_val(it):
              try: return float(it["value"].split("$")[1].split("/")[0])
              except Exception: return math.inf
          cheapest_items.sort(key=cost_val)
          cheapest_list = cheapest_items[:5]

          fastest_items = [{"name":k, "value": f"{int(round(v))} tokens/s"} for k,v in fast_best.items()]
          fastest_items.sort(key=lambda x: int(x["value"].split()[0]), reverse=True)
          fastest_list = fastest_items[:5]

          data = {
              "code": code_list,
              "multimodal": multi_list,
              "knowledge": know_list,
              "longest_context": longest_context,
              "cheapest": cheapest_list,
              "fastest": fastest_list
          }

          counts = {k: (len(v) if isinstance(v, list) else 0) for k, v in data.items()}
          print("SECTION COUNTS:", counts)

          with open("top-leaderboards.json","w",encoding="utf-8") as f:
              json.dump(data, f, indent=2, ensure_ascii=False)

          with open("build-log.json","w",encoding="utf-8") as f:
              json.dump({
                "generated_at_utc": datetime.datetime.utcnow().isoformat()+"Z",
                "section_counts": counts
              }, f, indent=2, ensure_ascii=False)

          print("OK: wrote top-leaderboards.json & build-log.json")
          print("\\n===== top-leaderboards.json (preview) =====")
          print(json.dumps(data, indent=2, ensure_ascii=False)[:2000])
          PY

      - name: Commit & push if changed
        run: |
          echo "Changed files (before):"; git status --porcelain || true
          if ! git diff --quiet -- top-leaderboards.json build-log.json; then
            git config user.name  "leaderboards-bot"
            git config user.email "actions@github.com"
            git add top-leaderboards.json build-log.json
            git commit -m "chore: build from official repo (recursive scan + model_benchmarks)"
            git push
          else
            echo "No changes to files"
          fi
          echo "Changed files (after):"; git status --porcelain || true
