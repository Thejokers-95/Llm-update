name: Build & Publish Top Leaderboards (from official repo)

on:
  schedule:
    - cron: "15 5 * * *"   # quotidien 05:15 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout (repo où publier le JSON)
        uses: actions/checkout@v4

      - name: Clone dépôt officiel (données)
        run: |
          rm -rf upstream
          git clone --depth=1 https://github.com/JonathanChavezTamales/llm-leaderboard.git upstream
          echo "== Dossiers trouvés =="
          find upstream/data -maxdepth 2 -type d -print | sed 's/^/ - /'
          echo "== Comptages JSON par dossier clé =="
          for d in models providers provider_models benchmarks model_benchmarks; do
            if [ -d "upstream/data/$d" ]; then
              echo "  $d: $(find upstream/data/$d -type f -name '*.json' | wc -l)"
              find upstream/data/$d -type f -name '*.json' | head -n 10 | sed 's/^/    - /'
            else
              echo "  $d: (absent)"
            fi
          done

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Build top-leaderboards.json (with discovery + fallbacks)
        run: |
          python - << 'PY'
          import os, re, json, math, datetime

          ROOT = "upstream/data"

          # -------- helpers --------
          def read_json(path):
            try:
              with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
            except Exception:
              return None

          def to_float(x):
            try: return float(x)
            except Exception: return None

          def normalize_score(v):
            f = to_float(v)
            if f is None: return None
            if f <= 1.0: f *= 100.0   # 0.884 -> 88.4
            return round(f, 1)

          def fmt_tokens(n):
            if n >= 1_000_000: return f"{n/1_000_000:.1f}M tokens"
            if n >= 1_000:     return f"{int(n/1000)}K tokens"
            return f"{int(n)} tokens"

          PRICE_KEYS = [
            "input_cost_per_million","input_cost","price_per_million",
            "price_per_1m_input_tokens","input_cost_per_1m","price_per_million_tokens"
          ]
          TPS_KEYS = ["tokens_per_second","throughput","tps","speed_tokens_per_second"]
          CODE_PAT = re.compile(r"(aider|polyglot|code)", re.I)
          MULTI_PAT= re.compile(r"(mmmu|multimodal|vision)", re.I)
          KNOW_PAT = re.compile(r"(gpqa)", re.I)

          # -------- accumulators --------
          code, multi, know = [], [], []
          ctx_map = {}
          cheap_map, fast_map = {}, {}

          # ===== PASS 1: fichiers attendus =====
          # model_benchmarks -> listes [ {name, score} ... ]
          mb_dir = os.path.join(ROOT, "model_benchmarks")
          if os.path.isdir(mb_dir):
            for fn in os.listdir(mb_dir):
              if not fn.endswith(".json"): continue
              bucket = None
              if CODE_PAT.search(fn):   bucket = "code"
              elif MULTI_PAT.search(fn):bucket = "multimodal"
              elif KNOW_PAT.search(fn): bucket = "knowledge"
              if not bucket: continue
              js = read_json(os.path.join(mb_dir, fn))
              if isinstance(js, list):
                items=[]
                for it in js:
                  if not isinstance(it, dict): continue
                  nm = it.get("name") or it.get("model") or it.get("id")
                  sc = normalize_score(it.get("score") or it.get("value"))
                  if nm and sc is not None: items.append({"name": nm, "score": sc})
                items.sort(key=lambda x: x["score"], reverse=True)
                if bucket=="code": code = items[:5]
                elif bucket=="multimodal": multi = items[:5]
                elif bucket=="knowledge": know = items[:5]

          # models -> contexte + (éventuels scores embarqués)
          models_dir = os.path.join(ROOT, "models")
          if os.path.isdir(models_dir):
            for fn in os.listdir(models_dir):
              if not fn.endswith(".json"): continue
              d = read_json(os.path.join(models_dir, fn))
              if not isinstance(d, dict): continue
              name = d.get("name") or d.get("model") or d.get("id") or os.path.splitext(fn)[0]
              # contexte
              for k in ["context_length","max_context_length","input_context","context","window"]:
                if k in d and d[k] not in (None, ""):
                  v = to_float(d[k])
                  if v is None:
                    s=str(d[k]).lower().replace("tokens","").strip()
                    mul=1
                    if "m" in s: s=s.replace("m",""); mul=1_000_000
                    elif "k" in s: s=s.replace("k",""); mul=1_000
                    try: v=float(s)*mul
                    except Exception: v=None
                  if v and v>0:
                    ctx_map[name] = max(ctx_map.get(name,0), int(v))
                  break

          # provider_models/providers -> prix / débit
          def absorb_provider_models(arr, prov_name, cheap_map, fast_map):
            if not isinstance(arr, list):
              return
            min_cost = cheap_map.get(prov_name, math.inf)
            max_tps  = fast_map.get(prov_name, 0.0)
            for m in arr:
              if not isinstance(m, dict): continue
              for pk in PRICE_KEYS:
                cf = to_float(m.get(pk))
                if cf is not None and cf < min_cost: min_cost = cf
              for tk in TPS_KEYS:
                tf = to_float(m.get(tk))
                if tf is not None and tf > max_tps: max_tps = tf
            if min_cost != math.inf: cheap_map[prov_name] = min_cost
            if max_tps  > 0:         fast_map[prov_name]  = max_tps

          pm_dir = os.path.join(ROOT,"provider_models")
          if os.path.isdir(pm_dir):
            for fn in os.listdir(pm_dir):
              if not fn.endswith(".json"): continue
              prov = os.path.splitext(fn)[0]
              arr = read_json(os.path.join(pm_dir, fn))
              absorb_provider_models(arr, prov, cheap_map, fast_map)

          prov_dir = os.path.join(ROOT,"providers")
          if os.path.isdir(prov_dir):
            for prov in os.listdir(prov_dir):
              path = os.path.join(prov_dir, prov, "models.json")
              if os.path.isfile(path):
                arr = read_json(path)
                absorb_provider_models(arr, prov, cheap_map, fast_map)

          # ===== PASS 2: scan global si sections vides =====
          if not code or not multi or not know or not ctx_map:
            for root, _, files in os.walk(ROOT):
              for fn in files:
                if not fn.endswith(".json"): continue
                p = os.path.join(root, fn)
                js = read_json(p)

                # listes génériques {name, score}
                if (not code or not multi or not know) and isinstance(js, list):
                  cand=[]
                  for it in js:
                    if isinstance(it, dict):
                      nm = it.get("name") or it.get("model") or it.get("id")
                      sc = normalize_score(it.get("score") or it.get("value"))
                      if nm and sc is not None:
                        cand.append({"name": nm, "score": sc})
                  if cand:
                    cand.sort(key=lambda x:x["score"], reverse=True)
                    base = (os.path.basename(root)+"/"+fn).lower()
                    if not code and CODE_PAT.search(base):        code = cand[:5]
                    if not multi and MULTI_PAT.search(base):      multi = cand[:5]
                    if not know and KNOW_PAT.search(base):        know = cand[:5]

                # contexte décousu
                if not ctx_map and isinstance(js, dict):
                  name = js.get("name") or js.get("model") or js.get("id") or os.path.splitext(fn)[0]
                  for k in ["context_length","max_context_length","input_context","context","window"]:
                    if k in js and js[k] not in (None, ""):
                      v = to_float(js[k])
                      if v is None:
                        s=str(js[k]).lower().replace("tokens","").strip()
                        mul=1
                        if "m" in s: s=s.replace("m",""); mul=1_000_000
                        elif "k" in s: s=s.replace("k",""); mul=1_000
                        try: v=float(s)*mul
                        except Exception: v=None
                      if v and v>0: ctx_map[name]=int(v)
                      break

          # ===== PASS 3: fallback README (si nécessaire)
          if (not multi or not know) or not code:
            try:
              readme = open("upstream/README.md","r",encoding="utf-8",errors="ignore").read()
            except Exception:
              readme = ""
            if readme:
              m = re.search(r"##\\s*Leaderboard(.+?)(?:\\n##|\\Z)", readme, re.S|re.I)
              if m:
                block = m.group(1)
                rows = [l.strip() for l in block.splitlines() if l.strip() and not l.strip().startswith("#")]
                parsed=[]
                for l in rows:
                  g=re.findall(r"^(.+?)\\s+.*?(0\\.\\d{3}|1\\.\\d{3}).*?(0\\.\\d{3}|1\\.\\d{3}).*$", l)
                  if g:
                    name=g[0][0].strip()
                    nums=[x for x in g[0][1:] if re.match(r"^[01]\\.\\d{3}$", x)]
                    if len(nums)>=2:
                      gpqa=normalize_score(nums[0]); mmmu=normalize_score(nums[1])
                      parsed.append((name,gpqa,mmmu))
                if parsed:
                  if not know:
                    know = [{"name":n,"score":s1} for (n,s1,_) in sorted(parsed, key=lambda x:x[1], reverse=True)[:5]]
                  if not multi:
                    multi = [{"name":n,"score":s2} for (n,_,s2) in sorted(parsed, key=lambda x:x[2], reverse=True)[:5]]
                  if not code:
                    # heuristique: 3ème nombre comme proxy "code" si dispo
                    he=[]
                    for l in rows:
                      h=re.findall(r"^(.+?)\\s+.*?([01]\\.\\d{3}).*?([01]\\.\\d{3}).*?([01]\\.\\d{3}).*?$", l)
                      if h:
                        name=h[0][0].strip()
                        val=normalize_score(h[0][3])
                        if val is not None: he.append({"name":name,"score":val})
                    he.sort(key=lambda x:x["score"], reverse=True)
                    code = he[:5] if he else code

          # -------- assemble --------
          ctx_list = [{"name":k, "value": fmt_tokens(v)} for k,v in sorted(ctx_map.items(), key=lambda kv: kv[1], reverse=True)[:5]]
          cheapest = [{"name":k, "value": f"${v:.2f} / 1M tokens"} for k,v in cheap_map.items()]
          def cost_val(it):
            try: return float(it["value"].split("$")[1].split("/")[0])
            except Exception: return math.inf
          cheapest.sort(key=cost_val)
          cheapest = cheapest[:5]
          fastest  = [{"name":k, "value": f"{int(round(v))} tokens/s"} for k,v in fast_map.items()]
          fastest.sort(key=lambda x: int(x["value"].split()[0]), reverse=True)
          fastest = fastest[:5]

          data = {
            "code": code[:5],
            "multimodal": multi[:5],
            "knowledge": know[:5],
            "longest_context": ctx_list,
            "cheapest": cheapest,
            "fastest": fastest
          }
          counts = {k: (len(v) if isinstance(v,list) else 0) for k,v in data.items()}
          print("SECTION COUNTS:", counts)

          with open("top-leaderboards.json","w",encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
          with open("build-log.json","w",encoding="utf-8") as f:
            json.dump({"generated_at_utc": datetime.datetime.utcnow().isoformat()+"Z",
                       "section_counts": counts}, f, indent=2, ensure_ascii=False)

          # aperçu
          print("\\n== Preview top-leaderboards.json ==")
          print(json.dumps(data, indent=2, ensure_ascii=False)[:2000])
          PY

      - name: Commit & push if changed
        run: |
          echo "Changed files (before):"; git status --porcelain || true
          if ! git diff --quiet -- top-leaderboards.json build-log.json; then
            git config user.name  "leaderboards-bot"
            git config user.email "actions@github.com"
            git add top-leaderboards.json build-log.json
            git commit -m "chore: build from official repo (discovery + fallbacks)"
            git push
          else
            echo "No changes to files"
          fi
          echo "Changed files (after):"; git status --porcelain || true
