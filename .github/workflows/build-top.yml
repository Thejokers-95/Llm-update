name: Build & Publish Top Leaderboards (from official repo)

on:
  schedule:
    - cron: "15 5 * * *"   # tous les jours à 05:15 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: python -m pip install requests

      - name: Write builder (models + model_benchmarks + provider_models)
        run: |
          cat > build_top.py << 'PY'
          import os, json, time, math, requests, re, sys, random, datetime
          from typing import Any, Dict, List

          OWNER="JonathanChavezTamales"; REPO="llm-leaderboard"
          API=f"https://api.github.com/repos/{OWNER}/{REPO}/contents/data"
          RAW=f"https://raw.githubusercontent.com/{OWNER}/{REPO}/main/data"

          S=requests.Session()
          S.headers.update({"Accept":"application/vnd.github+json","User-Agent":"llm-top-builder/4.0"})
          tok=os.getenv("GITHUB_TOKEN")
          if tok: S.headers["Authorization"]=f"Bearer {tok}"

          def _get(url, timeout=30, tries=4, backoff=0.6):
              err=None
              for i in range(tries):
                  try:
                      r=S.get(url, timeout=timeout)
                      if r.status_code==200: return r
                      if r.status_code in (429,403):
                          time.sleep(backoff*(2**i)+random.random()*0.2); continue
                      if r.status_code==404: return None
                      err=r
                  except Exception as e:
                      err=e
                  time.sleep(backoff*(i+1))
              return None

          def list_dir(path:str):
              r=_get(f"{API}/{path}".rstrip("/"))
              if not r: return []
              try:
                  d=r.json()
                  return d if isinstance(d,list) else []
              except: return []

          def fetch_json(path:str):
              r=_get(f"{RAW}/{path}".lstrip("/"))
              if not r: return None
              try: return r.json()
              except: return None

          def to_float(x):
              try: return float(x)
              except: return None

          def normalize_score(v):
              f = to_float(v)
              if f is None: return None
              if f <= 1.0: f *= 100.0
              return round(f, 1)

          # ---------- Providers (prix & débit)
          def collect_providers():
              cheap, fast = [], []
              # 1) provider_models/*.json
              for f in list_dir("provider_models"):
                  if f.get("type")!="file" or not f["name"].endswith(".json"): continue
                  prov = f["name"].removesuffix(".json")
                  arr = fetch_json(f"provider_models/{f['name']}")
                  if not isinstance(arr, list): continue
                  best_cost, best_thr = None, None
                  for m in arr:
                      c = m.get("input_cost_per_million") or m.get("input_cost") or m.get("price_per_million")
                      t = m.get("tokens_per_second") or m.get("throughput") or m.get("tps")
                      cf, tf = to_float(c), to_float(t)
                      if cf is not None: best_cost = cf if best_cost is None else min(best_cost, cf)
                      if tf is not None: best_thr  = tf if best_thr  is None else max(best_thr,  tf)
                  if best_cost is not None: cheap.append({"name":prov, "value": f"${best_cost:.2f} / 1M tokens"})
                  if best_thr  is not None: fast.append ({"name":prov, "value": f"{int(round(best_thr))} tokens/s"})

              # 2) fallback providers/*/models.json
              if not cheap or not fast:
                  for p in [i["name"] for i in list_dir("providers") if i.get("type")=="dir"]:
                      arr = fetch_json(f"providers/{p}/models.json")
                      if not isinstance(arr, list): continue
                      best_cost, best_thr = None, None
                      for m in arr:
                          c = m.get("input_cost_per_million") or m.get("input_cost") or m.get("price_per_million")
                          t = m.get("tokens_per_second") or m.get("throughput") or m.get("tps")
                          cf, tf = to_float(c), to_float(t)
                          if cf is not None: best_cost = cf if best_cost is None else min(best_cost, cf)
                          if tf is not None: best_thr  = tf if best_thr  is None else max(best_thr,  tf)
                      if best_cost is not None: cheap.append({"name":p, "value": f"${best_cost:.2f} / 1M tokens"})
                      if best_thr  is not None: fast.append ({"name":p, "value": f"{int(round(best_thr))} tokens/s"})

              def parse_cost(v):
                  try: return float(v.split("$")[1].split("/")[0].strip())
                  except: return math.inf
              cheap.sort(key=lambda x: parse_cost(x["value"]))
              fast.sort(key=lambda x: int(x["value"].split()[0]), reverse=True)
              return {"cheapest": cheap[:5], "fastest": fast[:5]}

          # ---------- Benchmarks modèles (code / multimodal / knowledge)
          def load_top_from_model_benchmarks():
              files = list_dir("model_benchmarks")
              names = [f["name"] for f in files if f.get("type")=="file" and f["name"].endswith(".json")]

              def load_first(match_regex):
                  pat = re.compile(match_regex, re.I)
                  cand = next((n for n in names if pat.search(n)), None)
                  if not cand: return []
                  js = fetch_json(f"model_benchmarks/{cand}")
                  items=[]
                  if isinstance(js, list):
                      for it in js:
                          nm = it.get("name") or it.get("model") or it.get("id")
                          sc = normalize_score(it.get("score") or it.get("value"))
                          if nm and sc is not None: items.append({"name":nm,"score":sc})
                  elif isinstance(js, dict):
                      for nm, sc in js.items():
                          sc = normalize_score(sc)
                          if sc is not None: items.append({"name":nm,"score":sc})
                  items.sort(key=lambda x:x["score"], reverse=True)
                  return items[:5]

              return {
                  "code":       load_first(r"(aider|polyglot|code)"),
                  "multimodal": load_first(r"(mmmu|multimodal|vision)"),
                  "knowledge":  load_first(r"(gpqa|knowledge)")
              }

          # ---------- Longest context (depuis data/models/*.json)
          def collect_longest_context():
              arr=[]
              for f in list_dir("models"):
                  if f.get("type")!="file" or not f["name"].endswith(".json"): continue
                  d = fetch_json(f"models/{f['name']}")
                  if not isinstance(d, dict): continue
                  name = d.get("name") or d.get("id") or f["name"].removesuffix(".json")
                  ctx  = d.get("context_length") or d.get("max_context_length") or d.get("input_context") or d.get("context") or d.get("window")
                  v = to_float(ctx)
                  if v is None and ctx is not None:
                      s=str(ctx).lower().replace("tokens","").strip()
                      mul=1
                      if "m" in s: s=s.replace("m",""); mul=1_000_000
                      elif "k" in s: s=s.replace("k",""); mul=1_000
                      try: v=float(s)*mul
                      except: v=None
                  if v and v>0: arr.append({"name":name,"_tokens":int(v)})

              arr.sort(key=lambda x:x["_tokens"], reverse=True)
              out=[]
              for r in arr[:5]:
                  n=r["_tokens"]
                  if n>=1_000_000: val=f"{n/1_000_000:.1f}M tokens"
                  elif n>=1000:    val=f"{int(n/1000)}K tokens"
                  else:            val=f"{int(n)} tokens"
                  out.append({"name":r["name"], "value": val})
              return out

          def main():
              top = load_top_from_model_benchmarks()
              top["longest_context"] = collect_longest_context()
              top.update(collect_providers())

              counts = {k: (len(v) if isinstance(v,list) else 0) for k,v in top.items()}
              print("SECTION COUNTS:", counts)

              with open("top-leaderboards.json","w",encoding="utf-8") as f:
                  json.dump(top, f, indent=2, ensure_ascii=False)

              # log détaillé (et timestamp pour commit)
              log = {
                "generated_at_utc": datetime.datetime.utcnow().isoformat()+"Z",
                "section_counts": counts
              }
              with open("build-log.json","w",encoding="utf-8") as f:
                  json.dump(log, f, indent=2, ensure_ascii=False)

              print("OK: wrote top-leaderboards.json & build-log.json")
              print("\\n===== top-leaderboards.json (preview) =====")
              print(json.dumps(top, indent=2, ensure_ascii=False)[:2000])

          if __name__=="__main__":
              main()
          PY

      - name: Run builder
        run: python build_top.py

      - name: Commit & push if changed
        run: |
          echo "Changed files (before):"; git status --porcelain || true
          if ! git diff --quiet -- top-leaderboards.json build-log.json; then
            git config user.name  "leaderboards-bot"
            git config user.email "actions@github.com"
            git add top-leaderboards.json build-log.json
            git commit -m "chore: daily build from official repo"
            git push
          else
            echo "No changes to files"
          fi
          echo "Changed files (after):"; git status --porcelain || true
